{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5778d8f-be2b-4995-911e-bb8796d1cd7b",
   "metadata": {},
   "source": [
    "# Binary SVC w/ Hiperparameter tunning (Grid Search, Random Search, Bayesian Opt, Bayes search, Optuna) & lifecycle management w/ MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc320901-2e6e-4e15-aaf7-516f04b8ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa librerias\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71eeb486-1bf1-484c-a978-8a1d5d1b5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts_setup/\")\n",
    "\n",
    "from my_config_loader import load_configuration_model_gen, \\\n",
    "                             load_configuration_mlflow, \\\n",
    "                             load_configuration_model_svc, \\\n",
    "                             load_configuration_model_knn\n",
    "\n",
    "from my_mlflow_utils import mlf_log_tags_params_gen, \\\n",
    "                            mlf_log_metrics_models, \\\n",
    "                            log_metrics_auc_intervals\n",
    "\n",
    "from my_data_processing_utils import save_datasets_to_csv,\\\n",
    "                      scale_dataset, \\\n",
    "                      split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c126e846-cafd-4519-b433-61dde14b2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress the warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"Distutils was imported before Setuptools\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Setuptools is replacing distutils.\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02353cc-8bc2-4dbc-9bd5-fb34c360e06a",
   "metadata": {},
   "source": [
    "## Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97823804-ba31-4f61-98d2-791107fd23e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
       "\n",
       "    fAlpha     fDist class  \n",
       "0  40.0920   81.8828     g  \n",
       "1   6.3609  205.2610     g  \n",
       "2  76.9600  256.7880     g  \n",
       "3  10.4490  116.7370     g  \n",
       "4   4.6480  356.4620     g  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lee dataset\n",
    "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\", \"class\"]\n",
    "df = pd.read_csv(\"../../data/raw/magic04.data\", names=cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f521222-4698-4ec5-b95d-447613e59667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['g', 'h'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores de la variable objetivo\n",
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed8ebe6-4574-4f45-a6d8-87f21645c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reclasifica variable objetivo - Class as int (g=1, h=0)\n",
    "\n",
    "df['class'] = (df['class'] == \"g\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bffe3a-f5b7-432e-ae62-cad3d2656ae8",
   "metadata": {},
   "source": [
    "### General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c76d052c-527c-49ae-857c-01d7a366d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Key to group & identify different runs\n",
    "# import datetime\n",
    "\n",
    "# mlf_key = datetime.datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "# # Load general parameters\n",
    "# import yaml\n",
    "\n",
    "# try:\n",
    "#     with open(\"../scripts_setup/General_params.yaml\") as f:\n",
    "#         config_file = yaml.safe_load(f)\n",
    "# except FileNotFoundError:\n",
    "#     raise FileNotFoundError(\"Configuration file not found\")\n",
    "\n",
    "# # General params\n",
    "# try:\n",
    "#     cv = config_file[\"General\"][\"cv\"]\n",
    "#     random_state = config_file[\"General\"][\"random_state\"]\n",
    "#     n_jobs = config_file[\"General\"][\"n_jobs\"]\n",
    "#     n_iter = config_file[\"General\"][\"n_iter\"]            # BayesSearchCV, BayesianOptimization, RandomizedSearchCV\n",
    "#     n_trials = config_file[\"General\"][\"n_trials\"]           # Optuna trials \n",
    "#     init_points = config_file[\"General\"][\"init_points\"]        # BayesianOptimization\n",
    "#     testing = config_file[\"General\"][\"testing\"]\n",
    "# except KeyError as e:\n",
    "#     raise KeyError(f\"Missing key in General section: {e}\")\n",
    "    \n",
    "# # MLFlow params\n",
    "# try:\n",
    "#     mlf_tracking_server_uri = config_file[\"MLFlow\"][\"tracking_server_uri\"]\n",
    "#     mlf_experiment_name = config_file[\"MLFlow\"][\"experiment_name\"]\n",
    "#     mlf_project_name = config_file[\"MLFlow\"][\"project_name\"]\n",
    "#     mlf_team = config_file[\"MLFlow\"][\"team\"]\n",
    "# except KeyError as e:\n",
    "#     raise KeyError(f\"Missing key in MLFlow section: {e}\")\n",
    "    \n",
    "# # SVC range params\n",
    "# try:\n",
    "#     c_min = config_file[\"SVC\"][\"c_min\"]\n",
    "#     c_max = config_file[\"SVC\"][\"c_max\"]\n",
    "#     gamma_min = config_file[\"SVC\"][\"gamma_min\"]\n",
    "#     gamma_max = config_file[\"SVC\"][\"gamma_max\"]\n",
    "# except KeyError as e:\n",
    "#     raise KeyError(f\"Missing key in SVC section: {e}\")\n",
    "\n",
    "# # KNN range params\n",
    "# try:\n",
    "#     n_neighbors_min = config_file[\"KNN\"][\"n_neighbors_min\"] \n",
    "#     n_neighbors_max = config_file[\"KNN\"][\"n_neighbors_max\"] \n",
    "#     leaf_size_min = config_file[\"KNN\"][\"leaf_size_min\"] \n",
    "#     leaf_size_max = config_file[\"KNN\"][\"leaf_size_max\"] \n",
    "# except KeyError as e:\n",
    "#     raise KeyError(f\"Missing key in KNN section: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02bb7fca-bb5c-4f39-86c3-7066f6b5137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configurations\n",
    "(mlf_key, \n",
    " cv, random_state, n_jobs, n_iter, n_trials, init_points, testing\n",
    ") = load_configuration_model_gen(\"../scripts_setup/General_params.yaml\")\n",
    "\n",
    "(mlf_tracking_server_uri, mlf_experiment_name, mlf_project_name, mlf_team\n",
    ") = load_configuration_mlflow(\"../scripts_setup/General_params.yaml\")\n",
    "\n",
    "(c_min, c_max, gamma_min, gamma_max\n",
    ") = load_configuration_model_svc(\"../scripts_setup/General_params.yaml\")\n",
    "\n",
    "(n_neighbors_min, n_neighbors_max, leaf_size_min, leaf_size_max \n",
    ") = load_configuration_model_knn(\"../scripts_setup/General_params.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b2a5afd-df1c-46a3-af73-82dbe022d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from config_loader_gen import load_configuration_gen\n",
    "# from config_loader_model import load_configuration_model\n",
    "\n",
    "# # Load configurations\n",
    "# (mlf_key, \n",
    "#  cv, random_state, n_jobs, n_iter, n_trials, init_points, testing, \n",
    "#  mlf_tracking_server_uri, mlf_experiment_name, mlf_project_name, mlf_team\n",
    "# ) = load_configuration_gen(\"../scripts_setup/General_params.yaml\")\n",
    "\n",
    "# (c_min, c_max, gamma_min, gamma_max, \n",
    "#  n_neighbors_min, n_neighbors_max, leaf_size_min, leaf_size_max \n",
    "# ) = load_configuration_model(\"../scripts_setup/General_params.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05803a91-391d-4714-b72d-e8f096c5bfcd",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d605234-e478-4a51-88b3-35fd6d4f6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle with a fixed random state for reproducibility\n",
    "# data_shuffled = df.sample(frac=1, random_state=random_state)  \n",
    "\n",
    "# # Split data into training and temporary sets (80% training, 20% temp)\n",
    "# df_train, df_temp = train_test_split(data_shuffled, test_size=0.4, random_state=random_state)\n",
    "\n",
    "# # Split the temporary set into testing and validation sets (50% test, 50% validation)\n",
    "# df_test, df_valid = train_test_split(df_temp, test_size=0.5, random_state=random_state)\n",
    "\n",
    "# # Reset the indices of the resulting DataFrames\n",
    "# df_train.reset_index(drop=True, inplace=True)\n",
    "# df_test.reset_index(drop=True, inplace=True)\n",
    "# df_valid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_train, df_test, df_valid = split_data(df, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea83b07-e47d-4f5f-b4c8-b337091dd13f",
   "metadata": {},
   "source": [
    "### Function for scaling and oversampling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe674a0-4406-4ab7-8be0-f9367415a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_dataset(df_param, random_state=None, oversample = False):\n",
    "#   X = df_param[df_param.columns[:-1]].values\n",
    "#   y = df_param[df_param.columns[-1]].values\n",
    "\n",
    "#   scaler = StandardScaler()\n",
    "#   X = scaler.fit_transform(X)\n",
    "\n",
    "#   if oversample:\n",
    "#     ros = RandomOverSampler(random_state=random_state)\n",
    "#     X, y = ros.fit_resample(X, y)\n",
    "\n",
    "#   data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
    "\n",
    "#   return data, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3d251-34b6-425e-bffb-3f7259e00008",
   "metadata": {},
   "source": [
    "### Scale & oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8cf543f-3371-4de7-b745-94f50752e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, X_train, y_train = scale_dataset(df_train, random_state, oversample = True)\n",
    "valid, X_valid, y_valid = scale_dataset(df_valid, random_state, oversample = False)\n",
    "test, X_test, y_test = scale_dataset(df_test, random_state, oversample = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96cd8e-78d6-4022-9f5f-d55694815f70",
   "metadata": {},
   "source": [
    "### Saves train / test / validation files & paths to log them in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50f7b08b-b884-43d7-bf2f-6ab5662a9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# # Save to CSV for logging\n",
    "# X_train_path = os.path.abspath(\"../../data/processed/X_train.csv\")\n",
    "# y_train_path = os.path.abspath(\"../../data/processed/y_train.csv\")\n",
    "# X_test_path = os.path.abspath(\"../../data/processed/X_test.csv\")\n",
    "# y_test_path = os.path.abspath(\"../../data/processed/y_test.csv\")\n",
    "# X_valid_path = os.path.abspath(\"../../data/processed/X_valid.csv\")\n",
    "# y_valid_path = os.path.abspath(\"../../data/processed/y_valid.csv\")\n",
    "\n",
    "# pd.DataFrame(X_train).to_csv(X_train_path, index=False)\n",
    "# pd.DataFrame(y_train).to_csv(y_train_path, index=False)\n",
    "# pd.DataFrame(X_test).to_csv(X_test_path, index=False)\n",
    "# pd.DataFrame(y_test).to_csv(y_test_path, index=False)\n",
    "# pd.DataFrame(X_valid).to_csv(X_valid_path, index=False)\n",
    "# pd.DataFrame(y_valid).to_csv(y_valid_path, index=False)\n",
    "\n",
    "# Call the function to save the datasets to CSV files\n",
    "dataset_paths = save_datasets_to_csv(X_train, y_train, X_test, y_test, X_valid, y_valid)\n",
    "\n",
    "# Access the file paths from the dictionary\n",
    "X_train_path = dataset_paths[\"X_train_path\"]\n",
    "y_train_path = dataset_paths[\"y_train_path\"]\n",
    "X_test_path = dataset_paths[\"X_test_path\"]\n",
    "y_test_path = dataset_paths[\"y_test_path\"]\n",
    "X_valid_path = dataset_paths[\"X_valid_path\"]\n",
    "y_valid_path = dataset_paths[\"y_valid_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f7283d-985e-462e-a5d7-b4f6c65f3f48",
   "metadata": {},
   "source": [
    "## MLFLow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f486c-a47c-4583-a41e-81f6c846a153",
   "metadata": {},
   "source": [
    "### Initialize MLFlow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a24eec5-e676-486a-a7e3-c68e6c86bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Code for init MLFLOW server: mlflow server --host 127.0.0.1 --port 5000\n",
    "#mlf_tracking_server_uri = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(mlf_tracking_server_uri)\n",
    "\n",
    "#mlf_experiment_name = \"Magic\"\n",
    "mlf_experiment_description = \"This is a(n) \" + mlf_experiment_name + \" experiment initiated on \" + mlf_key\n",
    "mlf_experiment_tags = {\n",
    "    \"project_name\": mlf_project_name,\n",
    "    \"team\": mlf_team,\n",
    "    \"mlflow.note.content\": mlf_experiment_description,\n",
    "}\n",
    "\n",
    "try:\n",
    "    mlf_exp_id = mlflow.create_experiment(name=mlf_experiment_name, tags=mlf_experiment_tags)\n",
    "except Exception as e:\n",
    "    mlf_exp_id = mlflow.get_experiment_by_name(mlf_experiment_name).experiment_id\n",
    "\n",
    "mlflow.sklearn.autolog(disable=True)    \n",
    "#print(\"Experiment ID:\", mlf_exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19267a8d-b640-4634-ad8d-7a3241cbb688",
   "metadata": {},
   "source": [
    "### MLFlow procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22fa51c8-6361-41ee-9e17-05da580b47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mlf_log_tags_params_gen(param_tag, *args):\n",
    "#     try:\n",
    "#         # Ensure the number of arguments is even (tag_name, value)\n",
    "#         if len(args) % 2 != 0:\n",
    "#             raise ValueError(\"Arguments must be provided in pairs (param_name, value)\")\n",
    "#         # Loop through pairs of arguments\n",
    "#         for i in range(0, len(args), 2):\n",
    "#             # Get tag name and value\n",
    "#             name = args[i]\n",
    "#             value = args[i + 1]\n",
    "#             if param_tag == \"tag\":          # Log tag\n",
    "#                 mlflow.set_tag(name, value)\n",
    "#             elif param_tag == \"param\":      # Log parameter\n",
    "#                 mlflow.log_param(name, value)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error mlf_log_tags_params_generic: {e}\")\n",
    "\n",
    "# def mlf_log_metrics_models(class_report, model, tag, auc):\n",
    "#     try:\n",
    "#         mlflow.log_metric(\"accuracy\", class_report[\"accuracy\"])\n",
    "#         mlflow.log_metric(\"AUC\", auc)\n",
    "        \n",
    "#         for class_name, metrics in class_report.items():\n",
    "#             if class_name not in [\"macro avg\", \"weighted avg\"]:\n",
    "#                 if isinstance(metrics, dict):  \n",
    "#                     for metric, value in metrics.items():\n",
    "#                         if metric in [\"precision\", \"recall\", \"f1-score\", \"support\"]:\n",
    "#                             mlflow.log_metric(f\"{metric}_{class_name}\", value)    \n",
    "#         #mlflow.log_figure(fig8, \"qq_plot.png\")\n",
    "#         mlflow.sklearn.log_model(model, tag) \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error mlf_log_metrics_models: {e}\")\n",
    "\n",
    "# def log_metrics_auc_intervals(svc_fpr, svc_tpr):\n",
    "#     try:\n",
    "#         # Define the intervals (e.g., 10%, 20%, ..., 90%)\n",
    "#         intervals = range(10, 91, 10)  # 10, 20, ..., 90        \n",
    "#         # Initialize a dictionary to store the AUC for each interval\n",
    "#         auc_intervals = {}        \n",
    "#         # Compute the total number of data points\n",
    "#         total_points = len(svc_fpr)\n",
    "        \n",
    "#         # Loop through each interval\n",
    "#         for interval in intervals:\n",
    "#             # Calculate the index up to which the current interval falls\n",
    "#             index = int((interval / 100) * total_points)            \n",
    "#             # Extract the FPR and TPR values up to the current index\n",
    "#             fpr_interval = svc_fpr[:index + 1]\n",
    "#             tpr_interval = svc_tpr[:index + 1]            \n",
    "#             # Compute the AUC for the current interval\n",
    "#             auc_interval = auc(fpr_interval, tpr_interval)            \n",
    "#             # Store the AUC for the current interval\n",
    "#             auc_intervals[interval] = auc_interval\n",
    "            \n",
    "#         for interval, auc_interval in auc_intervals.items():\n",
    "#             #print(f\"AUC for {interval}%: {auc_interval}\")  \n",
    "#             mlflow.log_metric(f\"AUC for {interval} perc\", auc_interval)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error log_metrics_auc_intervals: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461eb13b-0a10-4c55-bc42-d961d4264aa4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bdc144-78a5-4e73-8a75-147b7cb545b2",
   "metadata": {},
   "source": [
    "### KNN base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ccb59b7-bc3a-440a-b559-54599c122a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.12 s\n",
      "Wall time: 8.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Init MLFlow run\n",
    "with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_KNN_Baseline'):  \n",
    "    # Create KNN object, train & predict\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    y_pred_base_knn = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Get the hyperparameters of the trained model\n",
    "    best_params = knn_model.get_params()\n",
    "\n",
    "    # Log tags & params in MLFlow \n",
    "    mlf_log_tags_params_gen (\"tag\", \"cv\", cv, \"random_state\", random_state, \"n_jobs\", n_jobs, \"n_iter\", n_iter, \"n_trials\", n_trials, \"init_points\", init_points)\n",
    "    mlf_log_tags_params_gen (\"tag\", \"model_name\", \"KNN_Baseline\", \"model_description\", \"Baseline KNN\", \"X_train_path\", X_train_path, \"y_train_path\", y_train_path, \"X_test_path\", X_test_path, \"y_test_path\", y_test_path)\n",
    "    mlf_log_tags_params_gen(\"param\", \"n_neighbors\", best_params['n_neighbors'], \"weights\", best_params['weights'], \"algorithm\", best_params['algorithm'], \"leaf_size\", best_params['leaf_size'], \"p\", best_params['p'])\n",
    "        \n",
    "    # Values for getting AUC\n",
    "    base_knn_fpr, base_knn_tpr, threshold = roc_curve(y_test, y_pred_base_knn)\n",
    "    auc_knn_base = auc(base_knn_fpr, base_knn_tpr)\n",
    "    \n",
    "    # Log metrics & model in MLFlow\n",
    "    mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), knn_model, \"KNN_Baseline\", auc_knn_base)\n",
    "    \n",
    "    # End MLFlow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e7059-0ed5-457e-bc15-6c7dd6942112",
   "metadata": {},
   "source": [
    "### KNN Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb4b7487-c1ea-4c51-a154-71b42fac9707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=30, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=35, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=35, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=35, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=35, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=auto, leaf_size=35, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=auto, leaf_size=35, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "CPU times: total: 6.39 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# SVM Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "if testing:    \n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5],  # Number of neighbors to consider\n",
    "        'weights': ['distance'],  # Weighting function for predictions\n",
    "        'algorithm': ['auto'],  # Algorithm used to compute nearest neighbors\n",
    "        'leaf_size' : [30, 35],\n",
    "        'p' : [1]\n",
    "    }\n",
    "else:\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 10, 15, 20, 25, 30],  # Number of neighbors to consider\n",
    "        'weights': ['uniform', 'distance'],  # Weighting function for predictions\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute nearest neighbors\n",
    "        'leaf_size' : [leaf_size_min, leaf_size_max],\n",
    "        'p' : [1, 2]\n",
    "    }\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_knn = GridSearchCV(knn_model, param_grid, cv=cv, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Perform the grid search on training data\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Start MLFlow run\n",
    "with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_KNN_best_GridSearch'):  \n",
    "    #mlflow.sklearn.autolog()\n",
    "    \n",
    "    # Get hyperparameters of the best trained model\n",
    "    best_params = grid_search_knn.best_params_\n",
    "    \n",
    "    #print(best_params)\n",
    "    \n",
    "    # Get best trained model\n",
    "    best_knn = grid_search_knn.best_estimator_\n",
    "    \n",
    "    # train & predict\n",
    "    y_pred = best_knn.predict(X_test)\n",
    "    y_pred_gridsearch_knn = best_knn.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Log tags & params in MLFlow  \n",
    "    mlf_log_tags_params_gen (\"tag\", \"cv\", cv, \"random_state\", random_state, \"n_jobs\", n_jobs, \"n_iter\", n_iter, \"n_trials\", n_trials, \"init_points\", init_points)\n",
    "    mlf_log_tags_params_gen (\"tag\", \"model_name\", \"KNN_best_gridsearch\", \"model_description\", \"Best Grid Search KNN\", \"X_train_path\", X_train_path, \"y_train_path\", y_train_path, \"X_test_path\", X_test_path, \"y_test_path\", y_test_path)\n",
    "    mlf_log_tags_params_gen(\"param\", \"n_neighbors\", best_params['n_neighbors'], \"weights\", best_params['weights'], \"algorithm\", best_params['algorithm'], \"leaf_size\", best_params['leaf_size'], \"p\", best_params['p'])    # Values for getting AUC\n",
    "   \n",
    "    gridsearch_knn_fpr, gridsearch_knn_tpr, threshold = roc_curve(y_test, y_pred_gridsearch_knn)\n",
    "    auc_gridsearch_knn = auc(gridsearch_knn_fpr, gridsearch_knn_tpr)\n",
    "    \n",
    "    # Log metrics & model in MLFlow\n",
    "    mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), best_knn, \"KNN_best_GridSearch\", auc_gridsearch_knn)\n",
    "    log_metrics_auc_intervals(gridsearch_knn_fpr, gridsearch_knn_tpr)\n",
    "\n",
    "    # End MLFlow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1a7d9-8699-4818-9d64-3a693a5cd72f",
   "metadata": {},
   "source": [
    "### SVC Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba74a788-1f36-4b0f-a678-11094d15e04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] END algorithm=auto, leaf_size=34, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=34, n_neighbors=3, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=auto, leaf_size=34, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=30, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "CPU times: total: 3.89 s\n",
      "Wall time: 8.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# SVM Random search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define parameter distributions for the random search\n",
    "if testing:    \n",
    "    param_dist = {\n",
    "        'n_neighbors': randint(3, 5),  # Sample integer values between 1 and 20 for the number of neighbors\n",
    "        'weights': ['distance'],  # Choose between uniform and distance weighting\n",
    "        'algorithm': ['auto'],  # Choose between different algorithms\n",
    "        'leaf_size': randint(30, 35),  # Sample integer values between 10 and 100 for leaf size\n",
    "        'p': [1]  # Choose between Manhattan distance (1) and Euclidean distance (2)\n",
    "    }\n",
    "else:\n",
    "    param_dist = {\n",
    "        'n_neighbors': randint(n_neighbors_min, n_neighbors_max),  # Sample integer values between 1 and 20 for the number of neighbors\n",
    "        'weights': ['uniform', 'distance'],  # Choose between uniform and distance weighting\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Choose between different algorithms\n",
    "        'leaf_size': randint(leaf_size_min, leaf_size_max),  # Sample integer values between 10 and 100 for leaf size\n",
    "        'p': [1, 2]  # Choose between Manhattan distance (1) and Euclidean distance (2)\n",
    "    }\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search_knn = RandomizedSearchCV(knn_model, param_distributions=param_dist, cv=cv, n_iter=n_iter, random_state=random_state, verbose=2)\n",
    "\n",
    "# Perform the random search on the training data\n",
    "random_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Start MLFlow run\n",
    "with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_KNN_best_RandomSearch'):  \n",
    "    #mlflow.sklearn.autolog()\n",
    "    \n",
    "    # Get hyperparameters of the best trained model\n",
    "    best_params = random_search_knn.best_params_\n",
    "    \n",
    "    # Get best trained model\n",
    "    best_knn = random_search_knn.best_estimator_\n",
    "\n",
    "    # train & predict\n",
    "    y_pred = best_knn.predict(X_test)\n",
    "    y_pred_randomsearch_knn = best_knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Log tags & params in MLFlow\n",
    "    mlf_log_tags_params_gen (\"tag\", \"cv\", cv, \"random_state\", random_state, \"n_jobs\", n_jobs, \"n_iter\", n_iter, \"n_trials\", n_trials, \"init_points\", init_points)\n",
    "    mlf_log_tags_params_gen (\"tag\", \"model_name\", \"KNN_best_randomsearch\", \"model_description\", \"Best Random Search KNN\", \"X_train_path\", X_train_path, \"y_train_path\", y_train_path, \"X_test_path\", X_test_path, \"y_test_path\", y_test_path)\n",
    "    mlf_log_tags_params_gen(\"param\", \"n_neighbors\", best_params['n_neighbors'], \"weights\", best_params['weights'], \"algorithm\", best_params['algorithm'], \"leaf_size\", best_params['leaf_size'], \"p\", best_params['p'])    # Values for getting AUC\n",
    "    \n",
    "    # Values for getting AUC\n",
    "    randomsearch_knn_fpr, randomsearch_knn_tpr, threshold = roc_curve(y_test, y_pred_randomsearch_knn)\n",
    "    auc_randomsearch_knn = auc(randomsearch_knn_fpr, randomsearch_knn_tpr)\n",
    "\n",
    "    # Log metrics & model in MLFlow\n",
    "    mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), best_knn, \"SVC_best_RandomSearch\", auc_randomsearch_knn)\n",
    "    log_metrics_auc_intervals(randomsearch_knn_fpr, randomsearch_knn_tpr)\n",
    "\n",
    "    # End MLFlow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426885f8-aa14-40fd-8234-560aa6113229",
   "metadata": {},
   "source": [
    "### SVC Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94053ce1-58e6-4985-adff-b1eb57dc8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #InvalidParameterError: The 'n_neighbors' parameter of KNeighborsClassifier must be an int in the range [1, inf) or None. Got 4.0 instead.\n",
    "\n",
    "# %%time\n",
    "\n",
    "# # SVM Bayesian optimization - BayesianOptimization\n",
    "# from bayes_opt import BayesianOptimization\n",
    "\n",
    "# # KNN objective function with cross-validation\n",
    "# def knn_cv(n_neighbors: int):\n",
    "#     n_neighbors = int(n_neighbors)\n",
    "#     print(\"Type of n_neighbors:\", type(n_neighbors))\n",
    "#     print(\"Value of n_neighbors:\", n_neighbors)\n",
    "\n",
    "#     # Ensure n_neighbors is within allowed range (optional but recommended)\n",
    "#     if n_neighbors < 1 or n_neighbors >= 30:\n",
    "#         raise ValueError(\"n_neighbors must be between 1 and 29 (inclusive)\")\n",
    "    \n",
    "#     knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "#     scores = cross_val_score(knn, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "#     return np.mean(scores)\n",
    "\n",
    "# # Define the search space\n",
    "# pbounds_knn = {'n_neighbors': (3, 30)}\n",
    "# #pbounds_knn = dict(n_neighbors=range(3, 30))\n",
    "\n",
    "# # Create the Bayesian optimizer for KNN\n",
    "# bayes_optimizer_knn = BayesianOptimization(\n",
    "#     f=knn_cv,\n",
    "#     pbounds=pbounds_knn,\n",
    "#     random_state=random_state\n",
    "# )\n",
    "\n",
    "# # Perform the search on the training data\n",
    "# bayes_optimizer_knn.maximize(init_points=init_points, n_iter=n_iter)\n",
    "\n",
    "# # Start MLFlow run\n",
    "# with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_KNN_best_BayesianOptimization'):  \n",
    "#     #mlflow.sklearn.autolog()\n",
    "    \n",
    "#     # Get hyperparameters of the best trained model\n",
    "#     best_params = bayes_optimizer_knn.max['params']\n",
    "\n",
    "#     # Get best trained model    \n",
    "#     best_knn = KNeighborsClassifier(**best_params)\n",
    "#     # train & predict\n",
    "#     best_knn.fit(X_train, y_train)\n",
    "#     y_pred = best_knn.predict(X_test)\n",
    "#     y_pred_bayesianoptimization_knn = best_knn.decision_function(X_test)\n",
    "\n",
    "#     # Log tags & params in MLFlow\n",
    "#     mlf_log_tags_params_gen (\"tag\", \"cv\", cv, \"random_state\", random_state, \"n_jobs\", n_jobs, \"n_iter\", n_iter, \"n_trials\", n_trials, \"init_points\", init_points)\n",
    "#     mlf_log_tags_params_gen (\"tag\", \"model_name\", \"KNN_best_BayesianOptimization\", \"model_description\", \"Best Bayesian optimization KNN\", \"X_train_path\", X_train_path, \"y_train_path\", y_train_path, \"X_test_path\", X_test_path, \"y_test_path\", y_test_path)\n",
    "#     mlf_log_tags_params_gen(\"param\", \"n_neighbors\", best_params['n_neighbors'], \"weights\", best_params['weights'], \"algorithm\", best_params['algorithm'], \"leaf_size\", best_params['leaf_size'], \"p\", best_params['p'])    # Values for getting AUC\n",
    "    \n",
    "#     # Values for getting AUC\n",
    "#     bayesianoptimization_knn_fpr, bayesianoptimization_knn_tpr, threshold = roc_curve(y_test, y_pred_bayesianoptimization_knn)\n",
    "#     auc_bayesianoptimization_knn = auc(bayesianoptimization_knn_fpr, bayesianoptimization_knn_tpr)\n",
    "\n",
    "#     # Log metrics & model in MLFlow\n",
    "#     mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), best_knn, \"KNN_best_BayesianOptimization\", auc_bayesianoptimization_knn)\n",
    "#     log_metrics_auc_intervals(bayesianoptimization_knn_fpr, bayesianoptimization_knn_tpr)\n",
    "\n",
    "#     # End MLFlow run\n",
    "#     mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b7325-5cc6-4cec-b5d8-325f9a10187d",
   "metadata": {},
   "source": [
    "### SVC Bayes search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ba746c9-2e54-4a00-ad50-b4441f65aa09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:12\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# SVM Bayesian optimization - BayesSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Define the search space\n",
    "param_space = {\n",
    "    'C': (c_min, c_max, 'log-uniform'),  \n",
    "    'gamma': (gamma_min, gamma_max, 'log-uniform')  \n",
    "}\n",
    "\n",
    "# Initialize BayesSearchCV object\n",
    "bayes_search_svm = BayesSearchCV(\n",
    "    SVC(random_state=random_state), # pasar svc_model\n",
    "    param_space,\n",
    "    n_iter=n_iter,\n",
    "    n_jobs=n_jobs,\n",
    "    cv=cv\n",
    ")\n",
    "\n",
    "#print(bayes_search_svm.best_params_)\n",
    "\n",
    "# Perform the search on the training data\n",
    "bayes_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Start MLFlow run\n",
    "with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_SVC_best_BayesSearch'): \n",
    "    #mlflow.sklearn.autolog()\n",
    "    \n",
    "    # Get hyperparameters of the best trained model\n",
    "    best_params = bayes_search_svm.best_params_\n",
    "    \n",
    "    # Get best trained model\n",
    "    best_svc = bayes_search_svm.best_estimator_\n",
    "    # train & predict\n",
    "    \n",
    "    y_pred = best_svc.predict(X_test)\n",
    "    y_pred_bayessearch = best_svc.decision_function(X_test)\n",
    "    \n",
    "    # Log tags & params in MLFlow\n",
    "    mlf_log_tags_gen (cv, random_state, n_jobs, n_iter, n_trials, init_points, c_min, c_max, gamma_min, gamma_max)\n",
    "    mlf_log_tags_params(\"SVC_best_BayesSearch\", \"Best Bayes Search SVC\", best_params['C'], best_params['gamma'], best_svc.get_params()['kernel'], X_train_path, y_train_path, X_test_path, y_test_path)\n",
    "    \n",
    "    # Values for getting AUC\n",
    "    bayessearch_svc_fpr, bayessearch_svc_tpr, threshold = roc_curve(y_test, y_pred_bayessearch)\n",
    "    auc_bayessearch_svc = auc(bayessearch_svc_fpr, bayessearch_svc_tpr)\n",
    "    \n",
    "    # Log metrics & model in MLFlow\n",
    "    mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), best_svc, \"SVC_best_BayesSearch\", auc_bayessearch_svc)\n",
    "    log_metrics_auc_intervals(bayessearch_svc_fpr, bayessearch_svc_tpr)\n",
    "    \n",
    "    # End MLFlow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a30958-fd4f-4897-8ef7-6efe1ddf3aee",
   "metadata": {},
   "source": [
    "### SVC Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b39e4d6-f1a5-4470-9a98-029d4703c102",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# import optuna\n",
    "# from optuna.samplers import TPESampler\n",
    "# #import optuna.visualization as vis\n",
    "\n",
    "# # SVM objective function\n",
    "# def objective(trial):\n",
    "#     C = trial.suggest_float('C', c_min, c_max, log=True)\n",
    "#     gamma = trial.suggest_float('gamma', gamma_min, gamma_max, log=True)    \n",
    "#     kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n",
    "\n",
    "#     svc = SVC(C=C, gamma=gamma, kernel=kernel)\n",
    "    \n",
    "#     # Supongamos que X_train, y_train están definidos\n",
    "#     score = cross_val_score(svc, X_train, y_train, n_jobs=n_jobs, cv=cv).mean()\n",
    "\n",
    "#     # To save trials in current MLFlow run\n",
    "#     # with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_SVC_trial_Optuna_' + str(trial.number)):  \n",
    "#     #     mlflow.log_params(trial.params)\n",
    "#     #     mlflow.log_metric('score', score)\n",
    "#     #     # Set Optuna's trial id as the parent run ID for tracking\n",
    "#     #     mlflow.set_tag(\"parent_id\", str(trial.number))\n",
    "#     #     mlflow.end_run()\n",
    "#     return score\n",
    "\n",
    "# # Perform the search on the training data\n",
    "# pruner = optuna.pruners.MedianPruner()\n",
    "# study = optuna.create_study(sampler=TPESampler(), direction='maximize', pruner=pruner)\n",
    "# study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "# # Start MLFlow run\n",
    "# with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_SVC_best_Optuna'):  \n",
    "#     #mlflow.sklearn.autolog()\n",
    "    \n",
    "#     # Get hyperparameters of the best trained model\n",
    "#     best_params = study.best_params\n",
    "    \n",
    "#     # Get best trained model\n",
    "#     best_svc = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'])\n",
    "#     best_svc.fit(X_train, y_train)\n",
    "    \n",
    "#     # train & predict\n",
    "#     y_pred = best_svc.predict(X_test)\n",
    "#     y_pred_optuna = best_svc.decision_function(X_test)\n",
    "\n",
    "#     # Log tags & params in MLFlow\n",
    "#     mlf_log_tags_gen (cv, random_state, n_jobs, n_iter, n_trials, init_points, c_min, c_max, gamma_min, gamma_max)\n",
    "#     mlf_log_tags_params(\"SVC_best_Optuna\", \"Best Optuna SVC\", best_params['C'], best_params['gamma'], best_params['kernel'], X_train_path, y_train_path, X_test_path, y_test_path)\n",
    "\n",
    "#     # Values for getting AUC\n",
    "#     optuna_svc_fpr, optuna_svc_tpr, threshold = roc_curve(y_test, y_pred_optuna)\n",
    "#     auc_optuna_svc = auc(optuna_svc_fpr, optuna_svc_tpr)\n",
    "\n",
    "#     # Log metrics & model in MLFlow\n",
    "#     mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), best_svc, \"SVC_best_Optuna\", auc_optuna_svc)\n",
    "#     log_metrics_auc_intervals(optuna_svc_fpr, optuna_svc_tpr)\n",
    "\n",
    "#     # End MLFlow run\n",
    "#     mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdf6b5-67a2-420b-ac13-337faae86f5f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12, 12), dpi=150)\n",
    "# plt.plot(optuna_svc_fpr, optuna_svc_tpr, label='Optuna SVC (auc = %0.3f)' % auc_optuna_svc)\n",
    "# plt.plot(bayessearch_svc_fpr, bayessearch_svc_tpr, label='Bayes Search SVC (auc = %0.3f)' % auc_bayessearch_svc)\n",
    "# plt.plot(bayesianoptimization_svc_fpr, bayesianoptimization_svc_tpr, label='Bayesian optimization SVC (auc = %0.3f)' % auc_bayesianoptimization_svc)\n",
    "# plt.plot(randomsearch_svc_fpr, randomsearch_svc_tpr, label='Random search SVC (auc = %0.3f)' % auc_randomsearch_svc)\n",
    "# plt.plot(gridsearch_svc_fpr, gridsearch_svc_tpr, label='Grid search SVC (auc = %0.3f)' % auc_gridsearch_svc)\n",
    "# plt.plot(base_fpr, base_tpr, label='Base (auc = %0.3f)' % auc_base)\n",
    "\n",
    "# plt.xlabel('False Positive Rate -->')\n",
    "# plt.ylabel('True Positive Rate -->')\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d5f6fa-7162-454d-a015-ff89b22c30ff",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier\n",
    "RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbceb08a-22af-4fb9-9945-d44087e76ab0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import load_iris\n",
    "\n",
    "# # Load the Iris dataset\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "# # Create a Random Forest Classifier model\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# # Train the model on the training data\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = clf.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
