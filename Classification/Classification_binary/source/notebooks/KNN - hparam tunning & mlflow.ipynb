{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5778d8f-be2b-4995-911e-bb8796d1cd7b",
   "metadata": {},
   "source": [
    "# Binary SVC w/ Hiperparameter tunning (Grid Search, Random Search, Bayesian Opt, Bayes search, Optuna) & lifecycle management w/ MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc320901-2e6e-4e15-aaf7-516f04b8ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c126e846-cafd-4519-b433-61dde14b2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress the warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"Distutils was imported before Setuptools\")\n",
    "#warnings.filterwarnings(\"ignore\", message=\".*Setuptools is replacing distutils.*\", category=UserWarning, module='distutils')\n",
    "warnings.filterwarnings(\"ignore\", message=\"Setuptools is replacing distutils.\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02353cc-8bc2-4dbc-9bd5-fb34c360e06a",
   "metadata": {},
   "source": [
    "## Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97823804-ba31-4f61-98d2-791107fd23e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
       "\n",
       "    fAlpha     fDist class  \n",
       "0  40.0920   81.8828     g  \n",
       "1   6.3609  205.2610     g  \n",
       "2  76.9600  256.7880     g  \n",
       "3  10.4490  116.7370     g  \n",
       "4   4.6480  356.4620     g  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lee dataset\n",
    "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\", \"class\"]\n",
    "df = pd.read_csv(\"../../data/raw/magic04.data\", names=cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f521222-4698-4ec5-b95d-447613e59667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['g', 'h'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores de la variable objetivo\n",
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed8ebe6-4574-4f45-a6d8-87f21645c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reclasifica variable objetivo - Class as int (g=1, h=0)\n",
    "\n",
    "df['class'] = (df['class'] == \"g\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bffe3a-f5b7-432e-ae62-cad3d2656ae8",
   "metadata": {},
   "source": [
    "### General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c76d052c-527c-49ae-857c-01d7a366d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key to group & identify different runs\n",
    "import datetime\n",
    "\n",
    "mlf_key = datetime.datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "# Load general parameters\n",
    "import yaml\n",
    "\n",
    "with open(\"../scripts_setup/General_params.yaml\") as f:\n",
    "    config_file = yaml.safe_load(f)\n",
    "\n",
    "# General params\n",
    "cv = config_file[\"General\"][\"cv\"]\n",
    "random_state = config_file[\"General\"][\"random_state\"]\n",
    "n_jobs = config_file[\"General\"][\"n_jobs\"]\n",
    "n_iter = config_file[\"General\"][\"n_iter\"]            # BayesSearchCV, BayesianOptimization, RandomizedSearchCV\n",
    "n_trials = config_file[\"General\"][\"n_trials\"]           # Optuna trials \n",
    "init_points = config_file[\"General\"][\"init_points\"]        # BayesianOptimization\n",
    "testing = config_file[\"General\"][\"testing\"]\n",
    "# # SVC range params\n",
    "# c_min = config_file[\"SVC\"][\"c_min\"]\n",
    "# c_max = config_file[\"SVC\"][\"c_max\"]\n",
    "# gamma_min = config_file[\"SVC\"][\"gamma_min\"]\n",
    "# gamma_max = config_file[\"SVC\"][\"gamma_max\"]\n",
    "# MLFlow params\n",
    "mlf_tracking_server_uri = config_file[\"MLFlow\"][\"tracking_server_uri\"]\n",
    "mlf_experiment_name = config_file[\"MLFlow\"][\"experiment_name\"]\n",
    "mlf_project_name = config_file[\"MLFlow\"][\"project_name\"]\n",
    "mlf_team = config_file[\"MLFlow\"][\"team\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05803a91-391d-4714-b72d-e8f096c5bfcd",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d605234-e478-4a51-88b3-35fd6d4f6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle with a fixed random state for reproducibility\n",
    "data_shuffled = df.sample(frac=1, random_state=random_state)  \n",
    "\n",
    "# Split data into training and temporary sets (80% training, 20% temp)\n",
    "df_train, df_temp = train_test_split(data_shuffled, test_size=0.4, random_state=random_state)\n",
    "\n",
    "# Split the temporary set into testing and validation sets (50% test, 50% validation)\n",
    "df_test, df_valid = train_test_split(df_temp, test_size=0.5, random_state=random_state)\n",
    "\n",
    "# Reset the indices of the resulting DataFrames\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "df_valid.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea83b07-e47d-4f5f-b4c8-b337091dd13f",
   "metadata": {},
   "source": [
    "### Function for scaling and oversampling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe674a0-4406-4ab7-8be0-f9367415a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(df_param, random_state=None, oversample = False):\n",
    "  X = df_param[df_param.columns[:-1]].values\n",
    "  y = df_param[df_param.columns[-1]].values\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  X = scaler.fit_transform(X)\n",
    "\n",
    "  if oversample:\n",
    "    ros = RandomOverSampler(random_state=random_state)\n",
    "    X, y = ros.fit_resample(X, y)\n",
    "\n",
    "  data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
    "\n",
    "  return data, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3d251-34b6-425e-bffb-3f7259e00008",
   "metadata": {},
   "source": [
    "### Scale & oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8cf543f-3371-4de7-b745-94f50752e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, X_train, y_train = scale_dataset(df_train, random_state, oversample = True)\n",
    "valid, X_valid, y_valid = scale_dataset(df_valid, random_state, oversample = False)\n",
    "test, X_test, y_test = scale_dataset(df_test, random_state, oversample = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96cd8e-78d6-4022-9f5f-d55694815f70",
   "metadata": {},
   "source": [
    "### Saves train / test / validation files & paths to log them in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50f7b08b-b884-43d7-bf2f-6ab5662a9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Save to CSV for logging\n",
    "X_train_path = os.path.abspath(\"../../data/processed/X_train.csv\")\n",
    "y_train_path = os.path.abspath(\"../../data/processed/y_train.csv\")\n",
    "X_test_path = os.path.abspath(\"../../data/processed/X_test.csv\")\n",
    "y_test_path = os.path.abspath(\"../../data/processed/y_test.csv\")\n",
    "X_valid_path = os.path.abspath(\"../../data/processed/X_valid.csv\")\n",
    "y_valid_path = os.path.abspath(\"../../data/processed/y_valid.csv\")\n",
    "\n",
    "pd.DataFrame(X_train).to_csv(X_train_path, index=False)\n",
    "pd.DataFrame(y_train).to_csv(y_train_path, index=False)\n",
    "pd.DataFrame(X_test).to_csv(X_test_path, index=False)\n",
    "pd.DataFrame(y_test).to_csv(y_test_path, index=False)\n",
    "pd.DataFrame(X_valid).to_csv(X_valid_path, index=False)\n",
    "pd.DataFrame(y_valid).to_csv(y_valid_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f7283d-985e-462e-a5d7-b4f6c65f3f48",
   "metadata": {},
   "source": [
    "## MLFLow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f486c-a47c-4583-a41e-81f6c846a153",
   "metadata": {},
   "source": [
    "### Initialize MLFlow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a24eec5-e676-486a-a7e3-c68e6c86bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Code for init MLFLOW server: mlflow server --host 127.0.0.1 --port 5000\n",
    "#mlf_tracking_server_uri = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(mlf_tracking_server_uri)\n",
    "\n",
    "#mlf_experiment_name = \"Magic\"\n",
    "mlf_experiment_description = \"This is a(n) \" + mlf_experiment_name + \" experiment initiated on \" + mlf_key\n",
    "mlf_experiment_tags = {\n",
    "    \"project_name\": mlf_project_name,\n",
    "    \"team\": mlf_team,\n",
    "    \"mlflow.note.content\": mlf_experiment_description,\n",
    "}\n",
    "\n",
    "try:\n",
    "    mlf_exp_id = mlflow.create_experiment(name=mlf_experiment_name, tags=mlf_experiment_tags)\n",
    "except Exception as e:\n",
    "    mlf_exp_id = mlflow.get_experiment_by_name(mlf_experiment_name).experiment_id\n",
    "\n",
    "mlflow.sklearn.autolog(disable=True)    \n",
    "#print(\"Experiment ID:\", mlf_exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19267a8d-b640-4634-ad8d-7a3241cbb688",
   "metadata": {},
   "source": [
    "### MLFlow procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22fa51c8-6361-41ee-9e17-05da580b47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlf_log_tags_params_gen(param_tag, *args):\n",
    "    try:\n",
    "        # Ensure the number of arguments is even (tag_name, value)\n",
    "        if len(args) % 2 != 0:\n",
    "            raise ValueError(\"Arguments must be provided in pairs (param_name, value)\")\n",
    "        # Loop through pairs of arguments\n",
    "        for i in range(0, len(args), 2):\n",
    "            # Get tag name and value\n",
    "            name = args[i]\n",
    "            value = args[i + 1]\n",
    "            if param_tag == \"tag\":          # Log tag\n",
    "                mlflow.set_tag(name, value)\n",
    "            elif param_tag == \"param\":      # Log parameter\n",
    "                mlflow.log_param(name, value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error mlf_log_tags_params_generic: {e}\")\n",
    "\n",
    "def mlf_log_metrics_models(class_report, model, tag, auc):\n",
    "    try:\n",
    "        mlflow.log_metric(\"accuracy\", class_report[\"accuracy\"])\n",
    "        mlflow.log_metric(\"AUC\", auc)\n",
    "        \n",
    "        for class_name, metrics in class_report.items():\n",
    "            if class_name not in [\"macro avg\", \"weighted avg\"]:\n",
    "                if isinstance(metrics, dict):  \n",
    "                    for metric, value in metrics.items():\n",
    "                        if metric in [\"precision\", \"recall\", \"f1-score\", \"support\"]:\n",
    "                            mlflow.log_metric(f\"{metric}_{class_name}\", value)    \n",
    "        #mlflow.log_figure(fig8, \"qq_plot.png\")\n",
    "        mlflow.sklearn.log_model(model, tag) \n",
    "    except Exception as e:\n",
    "        print(f\"Error mlf_log_metrics_models: {e}\")\n",
    "\n",
    "def log_metrics_auc_intervals(svc_fpr, svc_tpr):\n",
    "    try:\n",
    "        # Define the intervals (e.g., 10%, 20%, ..., 90%)\n",
    "        intervals = range(10, 91, 10)  # 10, 20, ..., 90        \n",
    "        # Initialize a dictionary to store the AUC for each interval\n",
    "        auc_intervals = {}        \n",
    "        # Compute the total number of data points\n",
    "        total_points = len(svc_fpr)\n",
    "        \n",
    "        # Loop through each interval\n",
    "        for interval in intervals:\n",
    "            # Calculate the index up to which the current interval falls\n",
    "            index = int((interval / 100) * total_points)            \n",
    "            # Extract the FPR and TPR values up to the current index\n",
    "            fpr_interval = svc_fpr[:index + 1]\n",
    "            tpr_interval = svc_tpr[:index + 1]            \n",
    "            # Compute the AUC for the current interval\n",
    "            auc_interval = auc(fpr_interval, tpr_interval)            \n",
    "            # Store the AUC for the current interval\n",
    "            auc_intervals[interval] = auc_interval\n",
    "            \n",
    "        for interval, auc_interval in auc_intervals.items():\n",
    "            #print(f\"AUC for {interval}%: {auc_interval}\")  \n",
    "            mlflow.log_metric(f\"AUC for {interval} perc\", auc_interval)\n",
    "    except Exception as e:\n",
    "        print(f\"Error log_metrics_auc_intervals: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461eb13b-0a10-4c55-bc42-d961d4264aa4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bdc144-78a5-4e73-8a75-147b7cb545b2",
   "metadata": {},
   "source": [
    "### KNN base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccb59b7-bc3a-440a-b559-54599c122a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/15 19:12:58 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Init MLFlow run\n",
    "with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_KNN_Baseline'):  \n",
    "    # Create KNN object, train & predict\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    y_pred_base = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Get the hyperparameters of the trained model\n",
    "    best_params = knn_model.get_params()\n",
    "\n",
    "    # Log tags & params in MLFlow \n",
    "#    mlf_log_tags_gen (cv, random_state, n_jobs, n_iter, n_trials, init_points, c_min, c_max, gamma_min, gamma_max)\n",
    "#    mlf_log_tags_params(\"KNN_Baseline\", \"Baseline KNN\", \"\", \"\", \"\", X_train_path, y_train_path, X_test_path, y_test_path)\n",
    "    \n",
    "    mlf_log_tags_params_gen (\"tag\", \"cv\", cv, \"random_state\", random_state, \"n_jobs\", n_jobs, \"n_iter\", n_iter, \"n_trials\", n_trials, \"init_points\", init_points)\n",
    "    mlf_log_tags_params_gen (\"tag\", \"model_name\", \"KNN_Baseline\", \"model_description\", \"Baseline KNN\", \"X_train_path\", X_train_path, \"y_train_path\", y_train_path, \"X_test_path\", X_test_path, \"y_test_path\", y_test_path)\n",
    "    mlf_log_tags_params_gen(\"param\", \"n_neighbors\", best_params['n_neighbors'], \"weights\", best_params['weights'], \"algorithm\", best_params['algorithm'], \"leaf_size\", best_params['leaf_size'], \"p\", best_params['p'])\n",
    "        \n",
    "    # Values for getting AUC\n",
    "    base_fpr, base_tpr, threshold = roc_curve(y_test, y_pred_base)\n",
    "    auc_base = auc(base_fpr, base_tpr)\n",
    "    \n",
    "    # Log metrics & model in MLFlow\n",
    "    mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), knn_model, \"KNN_Baseline\", auc_base)\n",
    "    \n",
    "    # End MLFlow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd562993-2d42-4642-b6c2-4916c7b92d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e7059-0ed5-457e-bc15-6c7dd6942112",
   "metadata": {},
   "source": [
    "### KNN Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b7487-c1ea-4c51-a154-71b42fac9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# SVM Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "if testing:    \n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5],  # Number of neighbors to consider\n",
    "        'weights': ['distance'],  # Weighting function for predictions\n",
    "        'algorithm': ['auto'],  # Algorithm used to compute nearest neighbors\n",
    "        'leaf_size' : [30],\n",
    "        'p' : [1]\n",
    "    }\n",
    "else:\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9],  # Number of neighbors to consider\n",
    "        'weights': ['uniform', 'distance'],  # Weighting function for predictions\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute nearest neighbors\n",
    "        'leaf_size' : [30, 50],\n",
    "        'p' : [1, 2]\n",
    "    }\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_svc = GridSearchCV(knn_model, param_grid, cv=cv, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Perform the grid search on training data\n",
    "grid_search_svc.fit(X_train, y_train)\n",
    "\n",
    "# Start MLFlow run\n",
    "with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_KNN_best_GridSearch'):  \n",
    "    #mlflow.sklearn.autolog()\n",
    "    \n",
    "    # Get hyperparameters of the best trained model\n",
    "    best_params = grid_search_svc.best_params_\n",
    "    \n",
    "    print(best_params)\n",
    "    \n",
    "    # Get best trained model\n",
    "    best_svc = grid_search_svc.best_estimator_\n",
    "    \n",
    "    # train & predict\n",
    "    y_pred = best_svc.predict(X_test)\n",
    "    y_pred_gridsearch = best_svc.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Log tags & params in MLFlow  \n",
    "#    mlf_log_tags_gen (cv, random_state, n_jobs, n_iter, n_trials, init_points, c_min, c_max, gamma_min, gamma_max)\n",
    "#    mlf_log_tags_params(\"KNN_best_gridsearch\", \"Best Grid Search KNN\", best_params['C'], best_params['gamma'], best_params['kernel'], X_train_path, y_train_path, X_test_path, y_test_path)\n",
    "\n",
    "    mlf_log_tags_params_gen (\"tag\", \"cv\", cv, \"random_state\", random_state, \"n_jobs\", n_jobs, \"n_iter\", n_iter, \"n_trials\", n_trials, \"init_points\", init_points)\n",
    "    mlf_log_tags_params_gen (\"tag\", \"model_name\", \"KNN_best_gridsearch\", \"model_description\", \"Best Grid Search KNN\", \"X_train_path\", X_train_path, \"y_train_path\", y_train_path, \"X_test_path\", X_test_path, \"y_test_path\", y_test_path)\n",
    "    mlf_log_tags_params_gen(\"param\", \"n_neighbors\", best_params['n_neighbors'], \"weights\", best_params['weights'], \"algorithm\", best_params['algorithm'], \"leaf_size\", best_params['leaf_size'], \"p\", best_params['p'])    # Values for getting AUC\n",
    "   \n",
    "    gridsearch_svc_fpr, gridsearch_svc_tpr, threshold = roc_curve(y_test, y_pred_gridsearch)\n",
    "    auc_gridsearch_svc = auc(gridsearch_svc_fpr, gridsearch_svc_tpr)\n",
    "    \n",
    "    # Log metrics & model in MLFlow\n",
    "    mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), best_svc, \"KNN_best_GridSearch\", auc_gridsearch_svc)\n",
    "    log_metrics_auc_intervals(gridsearch_svc_fpr, gridsearch_svc_tpr)\n",
    "\n",
    "    # End MLFlow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1a7d9-8699-4818-9d64-3a693a5cd72f",
   "metadata": {},
   "source": [
    "### SVC Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74a788-1f36-4b0f-a678-11094d15e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# SVM Random search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define parameter distributions for the random search\n",
    "if testing:    \n",
    "    param_dist = {\n",
    "        'n_neighbors': randint(3, 5),  # Sample integer values between 1 and 20 for the number of neighbors\n",
    "        'weights': ['distance'],  # Choose between uniform and distance weighting\n",
    "        'algorithm': ['auto'],  # Choose between different algorithms\n",
    "        'leaf_size': randint(30, 35),  # Sample integer values between 10 and 100 for leaf size\n",
    "        'p': [1]  # Choose between Manhattan distance (1) and Euclidean distance (2)\n",
    "    }\n",
    "else:\n",
    "    param_dist = {\n",
    "        'n_neighbors': randint(1, 20),  # Sample integer values between 1 and 20 for the number of neighbors\n",
    "        'weights': ['uniform', 'distance'],  # Choose between uniform and distance weighting\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Choose between different algorithms\n",
    "        'leaf_size': randint(10, 100),  # Sample integer values between 10 and 100 for leaf size\n",
    "        'p': [1, 2]  # Choose between Manhattan distance (1) and Euclidean distance (2)\n",
    "    }\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search_svm = RandomizedSearchCV(knn_model, param_distributions=param_dist, cv=cv, n_iter=n_iter, random_state=random_state, verbose=2)\n",
    "\n",
    "# Perform the random search on the training data\n",
    "random_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Start MLFlow run\n",
    "with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_KNN_best_RandomSearch'):  \n",
    "    #mlflow.sklearn.autolog()\n",
    "    \n",
    "    # Get hyperparameters of the best trained model\n",
    "    best_params = random_search_svm.best_params_\n",
    "    \n",
    "    # Get best trained model\n",
    "    best_svc = random_search_svm.best_estimator_\n",
    "\n",
    "    # train & predict\n",
    "    y_pred = best_svc.predict(X_test)\n",
    "    y_pred_randomsearch = best_svc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Log tags & params in MLFlow\n",
    "    # mlf_log_tags_gen (cv, random_state, n_jobs, n_iter, n_trials, init_points, c_min, c_max, gamma_min, gamma_max)\n",
    "    # mlf_log_tags_params(\"SVC_best_randomsearch\", \"Best Random Search SVC\", best_params['C'], best_params['gamma'], best_params['kernel'], X_train_path, y_train_path, X_test_path, y_test_path)\n",
    "\n",
    "    mlf_log_tags_params_gen (\"tag\", \"cv\", cv, \"random_state\", random_state, \"n_jobs\", n_jobs, \"n_iter\", n_iter, \"n_trials\", n_trials, \"init_points\", init_points)\n",
    "    mlf_log_tags_params_gen (\"tag\", \"model_name\", \"KNN_best_randomsearch\", \"model_description\", \"Best Random Search KNN\", \"X_train_path\", X_train_path, \"y_train_path\", y_train_path, \"X_test_path\", X_test_path, \"y_test_path\", y_test_path)\n",
    "    mlf_log_tags_params_gen(\"param\", \"n_neighbors\", best_params['n_neighbors'], \"weights\", best_params['weights'], \"algorithm\", best_params['algorithm'], \"leaf_size\", best_params['leaf_size'], \"p\", best_params['p'])    # Values for getting AUC\n",
    "    \n",
    "    # Values for getting AUC\n",
    "    randomsearch_svc_fpr, randomsearch_svc_tpr, threshold = roc_curve(y_test, y_pred_randomsearch)\n",
    "    auc_randomsearch_svc = auc(randomsearch_svc_fpr, randomsearch_svc_tpr)\n",
    "\n",
    "    # Log metrics & model in MLFlow\n",
    "    mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), best_svc, \"SVC_best_RandomSearch\", auc_randomsearch_svc)\n",
    "    log_metrics_auc_intervals(randomsearch_svc_fpr, randomsearch_svc_tpr)\n",
    "\n",
    "    # End MLFlow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090dfef-5b0a-420f-a6f3-b50a395b6e70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # SVM Random search\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# # Define parameter distributions for the random search\n",
    "# param_dist = {'C': uniform(c_min, c_max),\n",
    "#               'gamma': ['scale', 'auto'],\n",
    "#  #'gamma': uniform(0.01, 10),\n",
    "#               'kernel': ['rbf', 'linear', 'poly']}\n",
    "\n",
    "# # Create the RandomizedSearchCV object\n",
    "# random_search_svm = RandomizedSearchCV(svc_model, param_distributions=param_dist, cv=cv, n_iter=n_iter, random_state=random_state, verbose=2)\n",
    "\n",
    "# # Perform the random search on the training data\n",
    "# random_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# # Start MLFlow run\n",
    "# with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_SVC_best_RandomSearch'):  \n",
    "#     #mlflow.sklearn.autolog()\n",
    "    \n",
    "#     # Get hyperparameters of the best trained model\n",
    "#     best_params = random_search_svm.best_params_\n",
    "    \n",
    "#     # Get best trained model\n",
    "#     best_svc = random_search_svm.best_estimator_\n",
    "\n",
    "#     # train & predict\n",
    "#     y_pred = best_svc.predict(X_test)\n",
    "#     y_pred_randomsearch = best_svc.decision_function(X_test)\n",
    "\n",
    "#     # Log tags & params in MLFlow\n",
    "#     mlf_log_tags_gen (cv, random_state, n_jobs, n_iter, n_trials, init_points, c_min, c_max, gamma_min, gamma_max)\n",
    "#     mlf_log_tags_params(\"SVC_best_randomsearch\", \"Best Random Search SVC\", best_params['C'], best_params['gamma'], best_params['kernel'], X_train_path, y_train_path, X_test_path, y_test_path)\n",
    "\n",
    "#     # Values for getting AUC\n",
    "#     randomsearch_svc_fpr, randomsearch_svc_tpr, threshold = roc_curve(y_test, y_pred_randomsearch)\n",
    "#     auc_randomsearch_svc = auc(randomsearch_svc_fpr, randomsearch_svc_tpr)\n",
    "\n",
    "#     # Log metrics & model in MLFlow\n",
    "#     mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), best_svc, \"SVC_best_RandomSearch\", auc_randomsearch_svc)\n",
    "#     log_metrics_auc_intervals(randomsearch_svc_fpr, randomsearch_svc_tpr)\n",
    "\n",
    "#     # End MLFlow run\n",
    "#     mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426885f8-aa14-40fd-8234-560aa6113229",
   "metadata": {},
   "source": [
    "### SVC Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94053ce1-58e6-4985-adff-b1eb57dc8cf4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # SVM Bayesian optimization - BayesianOptimization\n",
    "# from bayes_opt import BayesianOptimization\n",
    "\n",
    "# # To specify the kernel\n",
    "# kernel='rbf' \n",
    "\n",
    "# # SVM objective function with cross-validation\n",
    "# def svm_cv(C, gamma):    \n",
    "#     svm = SVC(C=C, gamma=gamma, kernel=kernel, random_state=random_state) ### en vez de usar svm se puede pasar el svc_model / capaz cambiar el nombre de la funcion?\n",
    "#     scores = cross_val_score(svm, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "#     return np.mean(scores)\n",
    "\n",
    "# # Define the search space\n",
    "# pbounds = {'C': (c_min, c_max), \n",
    "#            'gamma': (gamma_min, gamma_max)\n",
    "#           }\n",
    "\n",
    "# # Create the Bayesian optimizer\n",
    "# bayes_optimizer_svm = BayesianOptimization(\n",
    "#     f=svm_cv,\n",
    "#     pbounds=pbounds,\n",
    "#     random_state=random_state  \n",
    "# )\n",
    "\n",
    "# # Perform the search on the training data\n",
    "# bayes_optimizer_svm.maximize(init_points=init_points, n_iter=n_iter)\n",
    "\n",
    "# # Start MLFlow run\n",
    "# with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_SVC_best_BayesianOptimization'):  \n",
    "#     #mlflow.sklearn.autolog()\n",
    "    \n",
    "#     # Get hyperparameters of the best trained model\n",
    "#     best_params = bayes_optimizer_svm.max['params']\n",
    "\n",
    "#     # Get best trained model    \n",
    "#     best_svc = SVC(**best_params)\n",
    "#     # train & predict\n",
    "#     best_svc.fit(X_train, y_train)\n",
    "#     y_pred = best_svc.predict(X_test)\n",
    "#     y_pred_bayesianoptimization = best_svc.decision_function(X_test)\n",
    "\n",
    "#     # Log tags & params in MLFlow\n",
    "#     mlf_log_tags_gen (cv, random_state, n_jobs, n_iter, n_trials, init_points, c_min, c_max, gamma_min, gamma_max)\n",
    "#     mlf_log_tags_params(\"SVC_best_BayesianOptimization\", \"Best Bayesian Optimization SVC\", best_params['C'], best_params['gamma'], best_svc.get_params()['kernel'], X_train_path, y_train_path, X_test_path, y_test_path)\n",
    "\n",
    "#     # Values for getting AUC\n",
    "#     bayesianoptimization_svc_fpr, bayesianoptimization_svc_tpr, threshold = roc_curve(y_test, y_pred_bayesianoptimization)\n",
    "#     auc_bayesianoptimization_svc = auc(bayesianoptimization_svc_fpr, bayesianoptimization_svc_tpr)\n",
    "\n",
    "#     # Log metrics & model in MLFlow\n",
    "#     mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), best_svc, \"SVC_best_BayesianOptimization\", auc_bayesianoptimization_svc)\n",
    "#     log_metrics_auc_intervals(bayesianoptimization_svc_fpr, bayesianoptimization_svc_tpr)\n",
    "\n",
    "#     # End MLFlow run\n",
    "#     mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b7325-5cc6-4cec-b5d8-325f9a10187d",
   "metadata": {},
   "source": [
    "### SVC Bayes search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba746c9-2e54-4a00-ad50-b4441f65aa09",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # SVM Bayesian optimization - BayesSearchCV\n",
    "# from skopt import BayesSearchCV\n",
    "\n",
    "# # Define the search space\n",
    "# param_space = {\n",
    "#     'C': (c_min, c_max, 'log-uniform'),  \n",
    "#     'gamma': (gamma_min, gamma_max, 'log-uniform')  \n",
    "# }\n",
    "\n",
    "# # Initialize BayesSearchCV object\n",
    "# bayes_search_svm = BayesSearchCV(\n",
    "#     SVC(random_state=random_state), # pasar svc_model\n",
    "#     param_space,\n",
    "#     n_iter=n_iter,\n",
    "#     n_jobs=n_jobs,\n",
    "#     cv=cv\n",
    "# )\n",
    "\n",
    "# #print(bayes_search_svm.best_params_)\n",
    "\n",
    "# # Perform the search on the training data\n",
    "# bayes_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# # Start MLFlow run\n",
    "# with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_SVC_best_BayesSearch'): \n",
    "#     #mlflow.sklearn.autolog()\n",
    "    \n",
    "#     # Get hyperparameters of the best trained model\n",
    "#     best_params = bayes_search_svm.best_params_\n",
    "    \n",
    "#     # Get best trained model\n",
    "#     best_svc = bayes_search_svm.best_estimator_\n",
    "#     # train & predict\n",
    "    \n",
    "#     y_pred = best_svc.predict(X_test)\n",
    "#     y_pred_bayessearch = best_svc.decision_function(X_test)\n",
    "    \n",
    "#     # Log tags & params in MLFlow\n",
    "#     mlf_log_tags_gen (cv, random_state, n_jobs, n_iter, n_trials, init_points, c_min, c_max, gamma_min, gamma_max)\n",
    "#     mlf_log_tags_params(\"SVC_best_BayesSearch\", \"Best Bayes Search SVC\", best_params['C'], best_params['gamma'], best_svc.get_params()['kernel'], X_train_path, y_train_path, X_test_path, y_test_path)\n",
    "    \n",
    "#     # Values for getting AUC\n",
    "#     bayessearch_svc_fpr, bayessearch_svc_tpr, threshold = roc_curve(y_test, y_pred_bayessearch)\n",
    "#     auc_bayessearch_svc = auc(bayessearch_svc_fpr, bayessearch_svc_tpr)\n",
    "    \n",
    "#     # Log metrics & model in MLFlow\n",
    "#     mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), best_svc, \"SVC_best_BayesSearch\", auc_bayessearch_svc)\n",
    "#     log_metrics_auc_intervals(bayessearch_svc_fpr, bayessearch_svc_tpr)\n",
    "    \n",
    "#     # End MLFlow run\n",
    "#     mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a30958-fd4f-4897-8ef7-6efe1ddf3aee",
   "metadata": {},
   "source": [
    "### SVC Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b39e4d6-f1a5-4470-9a98-029d4703c102",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# import optuna\n",
    "# from optuna.samplers import TPESampler\n",
    "# #import optuna.visualization as vis\n",
    "\n",
    "# # SVM objective function\n",
    "# def objective(trial):\n",
    "#     C = trial.suggest_float('C', c_min, c_max, log=True)\n",
    "#     gamma = trial.suggest_float('gamma', gamma_min, gamma_max, log=True)    \n",
    "#     kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n",
    "\n",
    "#     svc = SVC(C=C, gamma=gamma, kernel=kernel)\n",
    "    \n",
    "#     # Supongamos que X_train, y_train estÃ¡n definidos\n",
    "#     score = cross_val_score(svc, X_train, y_train, n_jobs=n_jobs, cv=cv).mean()\n",
    "\n",
    "#     # To save trials in current MLFlow run\n",
    "#     # with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_SVC_trial_Optuna_' + str(trial.number)):  \n",
    "#     #     mlflow.log_params(trial.params)\n",
    "#     #     mlflow.log_metric('score', score)\n",
    "#     #     # Set Optuna's trial id as the parent run ID for tracking\n",
    "#     #     mlflow.set_tag(\"parent_id\", str(trial.number))\n",
    "#     #     mlflow.end_run()\n",
    "#     return score\n",
    "\n",
    "# # Perform the search on the training data\n",
    "# pruner = optuna.pruners.MedianPruner()\n",
    "# study = optuna.create_study(sampler=TPESampler(), direction='maximize', pruner=pruner)\n",
    "# study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "# # Start MLFlow run\n",
    "# with mlflow.start_run(experiment_id=mlf_exp_id, run_name= mlf_key + '_SVC_best_Optuna'):  \n",
    "#     #mlflow.sklearn.autolog()\n",
    "    \n",
    "#     # Get hyperparameters of the best trained model\n",
    "#     best_params = study.best_params\n",
    "    \n",
    "#     # Get best trained model\n",
    "#     best_svc = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'])\n",
    "#     best_svc.fit(X_train, y_train)\n",
    "    \n",
    "#     # train & predict\n",
    "#     y_pred = best_svc.predict(X_test)\n",
    "#     y_pred_optuna = best_svc.decision_function(X_test)\n",
    "\n",
    "#     # Log tags & params in MLFlow\n",
    "#     mlf_log_tags_gen (cv, random_state, n_jobs, n_iter, n_trials, init_points, c_min, c_max, gamma_min, gamma_max)\n",
    "#     mlf_log_tags_params(\"SVC_best_Optuna\", \"Best Optuna SVC\", best_params['C'], best_params['gamma'], best_params['kernel'], X_train_path, y_train_path, X_test_path, y_test_path)\n",
    "\n",
    "#     # Values for getting AUC\n",
    "#     optuna_svc_fpr, optuna_svc_tpr, threshold = roc_curve(y_test, y_pred_optuna)\n",
    "#     auc_optuna_svc = auc(optuna_svc_fpr, optuna_svc_tpr)\n",
    "\n",
    "#     # Log metrics & model in MLFlow\n",
    "#     mlf_log_metrics_models(classification_report(y_test, y_pred, output_dict=True), best_svc, \"SVC_best_Optuna\", auc_optuna_svc)\n",
    "#     log_metrics_auc_intervals(optuna_svc_fpr, optuna_svc_tpr)\n",
    "\n",
    "#     # End MLFlow run\n",
    "#     mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdf6b5-67a2-420b-ac13-337faae86f5f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12, 12), dpi=150)\n",
    "# plt.plot(optuna_svc_fpr, optuna_svc_tpr, label='Optuna SVC (auc = %0.3f)' % auc_optuna_svc)\n",
    "# plt.plot(bayessearch_svc_fpr, bayessearch_svc_tpr, label='Bayes Search SVC (auc = %0.3f)' % auc_bayessearch_svc)\n",
    "# plt.plot(bayesianoptimization_svc_fpr, bayesianoptimization_svc_tpr, label='Bayesian optimization SVC (auc = %0.3f)' % auc_bayesianoptimization_svc)\n",
    "# plt.plot(randomsearch_svc_fpr, randomsearch_svc_tpr, label='Random search SVC (auc = %0.3f)' % auc_randomsearch_svc)\n",
    "# plt.plot(gridsearch_svc_fpr, gridsearch_svc_tpr, label='Grid search SVC (auc = %0.3f)' % auc_gridsearch_svc)\n",
    "# plt.plot(base_fpr, base_tpr, label='Base (auc = %0.3f)' % auc_base)\n",
    "\n",
    "# plt.xlabel('False Positive Rate -->')\n",
    "# plt.ylabel('True Positive Rate -->')\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d5f6fa-7162-454d-a015-ff89b22c30ff",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier\n",
    "RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbceb08a-22af-4fb9-9945-d44087e76ab0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import load_iris\n",
    "\n",
    "# # Load the Iris dataset\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "# # Create a Random Forest Classifier model\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# # Train the model on the training data\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = clf.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
